import joblib

# ููุฏ ูุฏู
pipeline = joblib.load('models/toxic_model.pkl')

# ฺฉุงููุชโูุง ุชุณุช (ุณุงูู ู harmful)
tests = [
    "ููู ุนุงู ุจูุฏ ุฏูุช ฺฏุฑู",  # ุจุงุฏ clean
    "ุนุงู ุจูุฏ ููููู ุงุฒ ุฒุญูุงุชุชูู",  # clean
    "ฺฉุฑ ุชู ุฏููุช ุฎูู ุดู",  # ุจุงุฏ obscene ุง hateobscene
    "ฺฉุงูุงู ุชูฺฏุฑุงู ูพูุฑู ุจุง ุฎุตูุต",  # spamobscene
    "ูุนูุช ุจุฑู ฺฏู ุดู",  # hate
    "ูุญุตููุงุช ุฌูุณ ุงุตู ๐ฆ ุฏุงุฑฺฉุช"  # spamobscene
]

print("ุชุณุช ูพุดโุจู ูุฏู:\n")
for comment in tests:
    pred = pipeline.predict([comment])[0]
    print(f"ฺฉุงููุช: {comment}")
    print(f"ุชุดุฎุต: {pred}\n")